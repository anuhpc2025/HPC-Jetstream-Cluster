{
  "id": "HPL/Sithum/10-24 - 3 1",
  "suite": "HPL",
  "group": "Sithum",
  "run": "10-24 - 3 1",
  "dat": {
    "raw": "HPLinpack benchmark input file\nInnovative Computing Laboratory, University of Tennessee\nHPL.out      output file name (if any) \n6            device out (6=stdout,7=stderr,file)\n1            # of problems sizes (N)\n300000         Ns\n1            # of NBs\n384           NBs\n0            PMAP process mapping (0=Row-,1=Column-major)\n1            # of process grids (P x Q)\n8            Ps\n32            Qs\n16.0         threshold\n1            # of panel fact\n2            PFACTs (0=left, 1=Crout, 2=Right)\n1            # of recursive stopping criterium\n4            NBMINs (>= 1)\n1            # of panels in recursion\n2            NDIVs\n1            # of recursive panel fact.\n1            RFACTs (0=left, 1=Crout, 2=Right)\n1            # of broadcast\n1            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM)\n1            # of lookahead depth\n1            DEPTHs (>=0)\n2            SWAP (0=bin-exch,1=long,2=mix)\n64           swapping threshold\n0            L1 in (0=transposed,1=no-transposed) form\n0            U  in (0=transposed,1=no-transposed) form\n1            Equilibration (0=no,1=yes)\n8            memory alignment in double (> 0)\n##### This line (no. 32) is ignored (it serves as a separator). ######\n0                               Number of additional problem sizes for PTRANS\n1200 10000 30000                values of N\n0                               number of additional blocking sizes for PTRANS\n40 9 8 13 13 20 16 32 64        values of NB",
    "parsed": {
      "header": [
        "HPLinpack benchmark input file",
        "Innovative Computing Laboratory, University of Tennessee"
      ],
      "outputFilename": "HPL.out",
      "deviceOut": 6,
      "numProblemSizes": 1,
      "Ns": [
        300000
      ],
      "numNBs": 1,
      "NBs": [
        384
      ],
      "pmap": 0,
      "numGrids": 1,
      "Ps": [
        8
      ],
      "Qs": [
        32
      ],
      "threshold": 16,
      "numPFACT": 1,
      "PFACTs": [
        2,
        0,
        1,
        2
      ],
      "numNBMIN": 1,
      "NBMINs": [
        4,
        1
      ],
      "numPanelsInRecursion": 1,
      "NDIVs": [
        2
      ],
      "numRFACT": 1,
      "RFACTs": [
        1,
        0,
        1,
        2
      ],
      "numBCAST": 1,
      "BCASTs": [
        1,
        0,
        1,
        1,
        1,
        2,
        2,
        3,
        2,
        4,
        5
      ],
      "numDEPTH": 1,
      "DEPTHs": [
        1,
        0
      ],
      "swapMode": 2,
      "swapThreshold": 64,
      "L1": 0,
      "U": 0,
      "equilibration": 1,
      "memoryAlignment": 8
    },
    "path": "/raw/HPL/Sithum/10-24 - 3 1/HPL.dat"
  },
  "job": {
    "filename": "run.sh",
    "raw": "#!/bin/bash\n#SBATCH --job-name=hpl-test       # Job name\n#SBATCH --ntasks=256              # Total MPI tasks\n#SBATCH --ntasks-per-node=64       # MPI tasks per node\n#SBATCH --cpus-per-task=1         # CPU cores per MPI task\n#SBATCH --time=24:00:00           # Time limit hh:mm:ss\n#SBATCH --nodes=4                 # Number of nodes\n\nexport SPACK_USER_CONFIG_PATH=/tmp/spack-config\nexport SPACK_USER_CACHE_PATH=/tmp/spack-cache\n\nexport SPACK_ROOT=/opt/spack\nsource ${SPACK_ROOT}/share/spack/setup-env.sh\n\n# Load OpenMPI explicitly by hash\nspack load /buou2hh\nspack load hpl %aocc\n\nunset OMPI_MCA_osc\n\n# MPI settings (Ethernet)\nexport OMPI_MCA_btl=self,vader,tcp\nexport OMPI_MCA_btl_tcp_if_include=eth0\nexport OMPI_MCA_oob_tcp_if_include=eth0\nexport OMPI_MCA_pml=ob1\n\n# Collective tuning\nexport OMPI_MCA_coll_tuned_use_dynamic_rules=1\nexport OMPI_MCA_coll_tuned_bcast_algorithm=4\nexport OMPI_MCA_coll_tuned_allreduce_algorithm=6\n\n# SLURM Integration\nexport OMPI_MCA_plm=slurm\nexport OMPI_MCA_orte_launch=slurm\n\n# Thread binding and OpenMP\nexport OMP_NUM_THREADS=1\nexport OMP_PROC_BIND=close\nexport OMP_PLACES=cores\n\n# amdblis (BLAS layer) optimizations\nexport BLIS_JC_NT=1  # (No outer loop parallelization)\nexport BLIS_IC_NT=$OMP_NUM_THREADS # (# of 2nd level threads â€“ one per core in the shared L3 cache domain):\nexport BLIS_JR_NT=1 # (No 4th level threads)\nexport BLIS_IR_NT=1 # (No 5th level threads)\n\n# Memory and file limits\nulimit -l unlimited\nulimit -n 65536\n\n# Flush any pending writes\nsync\n\n# Drop caches\necho 3 | sudo tee /proc/sys/vm/drop_caches >/dev/null\n\n# Forces memory compaction\necho 1 > /proc/sys/vm/compact_memory\n\n# Run the MPI program\nmpirun $(spack location -i hpl)/bin/xhpl",
    "sbatch": {
      "job-name": "hpl-test       # Job name",
      "ntasks": null,
      "ntasks-per-node": null,
      "cpus-per-task": null,
      "time": "24:00:00           # Time limit hh:mm:ss",
      "nodes": null
    },
    "path": "/raw/HPL/Sithum/10-24 - 3 1/run.sh"
  },
  "out": {
    "path": "/raw/HPL/Sithum/10-24 - 3 1/run.sh-40.out",
    "runs": [
      {
        "tv": "WR11C2R4",
        "N": 300000,
        "NB": 384,
        "P": 8,
        "Q": 32,
        "timeSec": 3145.73,
        "gflops": 5722.1,
        "startTime": "Fri Oct 24 02:09:53 2025",
        "endTime": "Fri Oct 24 03:02:18 2025",
        "residual": 0.00160942509,
        "residualPassed": true
      }
    ],
    "summary": {
      "testsTotal": 1,
      "testsPassed": 1,
      "testsFailed": 0,
      "testsSkipped": 0
    }
  },
  "err": null,
  "best": {
    "gflops": 5722.1,
    "N": 300000,
    "NB": 384,
    "timeSec": 3145.73
  }
}